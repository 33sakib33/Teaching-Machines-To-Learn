{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4700aac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "09bada09",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"txt_data.txt\") as f:\n",
    "    text_corpus=f.read();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "588a174a",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed=re.split(r'([,.?!\"()\\']|--|\\s)',text_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e9f7182e",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed = [item for item in preprocessed if item.strip()]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4146b38b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6179\n"
     ]
    }
   ],
   "source": [
    "allwords = sorted(list(set(preprocessed)))\n",
    "allwords.extend([\"<|endoftext|>\",\"<|unk|>\"])\n",
    "vocabsize = len(allwords)\n",
    "print(vocabsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7a969a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary={token:idx for idx,token in enumerate(allwords)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1ca907ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleTokenizer:\n",
    "    def __init__(self, vocab):\n",
    "        self.str_to_int=vocab;\n",
    "        self.int_to_str={i:s for s,i in vocab.items()}\n",
    "    def encode(self,text):\n",
    "        preprocessed=re.split(r'([,.?!\"()\\']|--|\\s)',text)\n",
    "        preprocessed = [item for item in preprocessed if item.strip()]\n",
    "        preprocessed = [item if item in self.str_to_int.keys() else \"<|unk|>\" for item in preprocessed]\n",
    "        ids=[self.str_to_int[x] for x in preprocessed]\n",
    "        return ids;\n",
    "    def decode(self,ids):\n",
    "\n",
    "        text=\" \".join(self.int_to_str[i] for i in ids)\n",
    "\n",
    "        text = re.sub(r'\\s+([,.?!\"()\\'])',r'\\1', text)\n",
    "        return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0092bb32",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tokenizer = SimpleTokenizer(vocabulary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "35ff101b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_text=\"A goal welcome in the mountainside\";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "db76dabd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1130, 3588, 6030, 3789, 5679, 6178]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.encode(sample_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1f4b81cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A goal welcome in the <|unk|>'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(tokenizer.encode(sample_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "84bb94e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#use better encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "099ddf12",
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib.metadata import version\n",
    "import tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b29d6361",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8.0\n"
     ]
    }
   ],
   "source": [
    "print(version(\"tiktoken\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "81e74025",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer = tiktoken.get_encoding(\"gpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2941fd0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# enc_text=tiktoken.encode(text_corpus)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "924fc0ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_text=tokenizer.encode(text_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "80afb3be",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_enc=enc_text[550:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ad7e36ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "context_size = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1569c583",
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y=sample_enc[:context_size],sample_enc[1:context_size+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ba32deec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: [2677, 5860, 2244, 3568]\n",
      "y:        [5860, 2244, 3568, 2114]\n"
     ]
    }
   ],
   "source": [
    "print(f\"x: {x}\")\n",
    "print(f\"y:        {y}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4b0e667d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "complex ----> understanding\n",
      "complex understanding ----> and\n",
      "complex understanding and ----> generation\n",
      "complex understanding and generation ----> abilities\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, context_size+1):\n",
    "    context = sample_enc[:i]\n",
    "    desired = sample_enc[i]\n",
    "    print(tokenizer.decode(context),\"---->\", tokenizer.decode([desired]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "447a4e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "de606112",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class GPTDataset(Dataset):\n",
    "    def __init__(self,txt, tokenizer, max_length,stride):\n",
    "        self.tokenizer=tokenizer;\n",
    "        self.input_ids=[]\n",
    "        self.target_ids=[]\n",
    "        token_ids=self.tokenizer.encode(txt);\n",
    "\n",
    "        for i in range(0,len(token_ids)-max_length,stride):\n",
    "            X_chunk=token_ids[i:i+max_length];\n",
    "            y_chunk=token_ids[i+1:i+max_length+1];\n",
    "\n",
    "            self.input_ids.append(torch.tensor((X_chunk)))\n",
    "            self.target_ids.append(torch.tensor((y_chunk)))\n",
    "\n",
    "            \n",
    "            \n",
    "    def __len__(self):\n",
    "        return len(self.input_ids)\n",
    "    def __getitem__(self,idx):\n",
    "        return self.input_ids[idx],self.target_ids[idx];\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "72ef7855",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset= GPTDataset(text_corpus,tokenizer,5,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "28e190d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7699f754",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataloader(txt,vocab,tokenizer_class,batch_size=4,max_length=256,stride=128,shuffle=True,drop_last=True,num_workers=0):\n",
    "    tokenizer=tokenizer_class(vocab);\n",
    "    dataset=GPTDataset(txt,tokenizer,max_length,stride)\n",
    "    dataloader = DataLoader(\n",
    "        dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=shuffle,\n",
    "        drop_last=drop_last,\n",
    "        num_workers=num_workers\n",
    "    )\n",
    "    return dataloader;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "311e91f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader=create_dataloader(text_corpus,vocabulary,SimpleTokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "e3990d7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = create_dataloader(\n",
    "    text_corpus, vocabulary, SimpleTokenizer,batch_size=4, max_length=4, stride=16, shuffle=False\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "a5e54fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dim=256\n",
    "token_embedding_layer=torch.nn.Embedding(len(vocabulary),output_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "42facd3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(6177, 256)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_embedding_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "e0230ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_iter=iter(dataloader)\n",
    "input,target=next(data_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "eb94189d",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_embd=token_embedding_layer(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "fa259752",
   "metadata": {},
   "outputs": [],
   "source": [
    "context_length=4;\n",
    "output_dim=256\n",
    "pos_embedding_layer=torch.nn.Embedding(context_length,output_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "2175dd04",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_pos=pos_embedding_layer(torch.arange(context_length))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "71525dc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 4, 256])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(token_embd+output_pos).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "cdc4345a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x107db5470>"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "ef8b95fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "input= torch.rand(6,6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "08b8cf56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0772, 0.3565, 0.1479, 0.5331, 0.4066, 0.2318],\n",
       "        [0.4545, 0.9737, 0.4606, 0.5159, 0.4220, 0.5786],\n",
       "        [0.9455, 0.8057, 0.6775, 0.6087, 0.6179, 0.6932],\n",
       "        [0.4354, 0.0353, 0.1908, 0.9268, 0.5299, 0.0950],\n",
       "        [0.5789, 0.9131, 0.0275, 0.1634, 0.3009, 0.5201],\n",
       "        [0.3834, 0.4451, 0.0126, 0.7341, 0.9389, 0.8056]])"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "7cf90c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "query=input[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "61f0e006",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.2392)\n",
      "tensor(1.4211)\n",
      "tensor(0.9672)\n",
      "tensor(1.6398)\n",
      "tensor(1.9152)\n",
      "tensor(0.8563)\n",
      "tensor(1.2123)\n",
      "tensor(1.3347)\n",
      "tensor(1.2462)\n",
      "tensor(1.2325)\n"
     ]
    }
   ],
   "source": [
    "for x,y in enumerate(input):\n",
    "    print(y@query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "1c92b55a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# query=query.unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "93dbb6e3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6])"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "09f1e7df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 6])"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "4b1bdab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dot=query @ input.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "843d20c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2.2392, 1.4211, 0.9672, 1.6398, 1.9152, 0.8563, 1.2123, 1.3347, 1.2462,\n",
       "        1.2325])"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "fd35569b",
   "metadata": {},
   "outputs": [],
   "source": [
    "norm=torch.softmax(dot,dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "95cd9617",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.)"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "2a22a2c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pair_wise_attn= input @ input.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "4b8c47c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_attn=torch.softmax(pair_wise_attn,dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "72a968e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "        1.0000])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm_attn.sum(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "19c1992b",
   "metadata": {},
   "outputs": [],
   "source": [
    "wk=nn.Parameter(torch.rand(6,3),requires_grad=True);\n",
    "wq=nn.Parameter(torch.rand(6,3),requires_grad=True);\n",
    "wv=nn.Parameter(torch.rand(6,3),requires_grad=True);\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "baca682a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=input[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "7aa1621e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.8089, 0.5460, 0.8383, 0.5359, 0.1298, 0.7184])"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "68bed27e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[0.3632, 0.1988, 0.5198],\n",
       "        [0.9128, 0.9011, 0.5084],\n",
       "        [0.9404, 0.5893, 0.9334],\n",
       "        [0.4826, 0.9069, 0.3541],\n",
       "        [0.6769, 0.4524, 0.4210],\n",
       "        [0.2534, 0.0338, 0.2954]], requires_grad=True)"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "065683b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.1092, grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(wk[:,0]*x).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "78e96e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "k=x @ wk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "abb57fea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2.1875, 2.0642, 1.4362], grad_fn=<SqueezeBackward4>)\n"
     ]
    }
   ],
   "source": [
    "query= x@ wq\n",
    "print(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "aef6d6e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "keys= input @ wk\n",
    "queries= input @ wq\n",
    "values= input @ wv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "28362171",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.7492, 1.3924, 1.3594], grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keys[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "7690a0a9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(10.9380, grad_fn=<DotBackward0>)\n"
     ]
    }
   ],
   "source": [
    "k2=keys[1]\n",
    "q2=queries[1]\n",
    "attn_kq= query.dot(k2)\n",
    "print(attn_kq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "86698002",
   "metadata": {},
   "outputs": [],
   "source": [
    "attn_scors= q2 @ keys.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "629e0d3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 8.6529, 10.9380, 10.8418, 12.5827, 11.4919,  8.3091,  7.9694,  7.6344,\n",
       "         7.8425,  5.9916], grad_fn=<SqueezeBackward4>)"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attn_scors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "90a4e94e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "class AttentionBlock(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.context_len=6;\n",
    "        self.wk=nn.Linear(6,4);\n",
    "        self.wq=nn.Linear(6,4);\n",
    "        self.wv=nn.Linear(6,4);\n",
    "        self.dropout=torch.nn.dropout(.5)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        q= self.wq(x);\n",
    "        k=self.wk(x);\n",
    "        v= self.wv(x);\n",
    "        attn_score= q @ k.T\n",
    "        \n",
    "        attn_weights= torch.softmax(attn_score/k.shape[-1]**0.5,dim=-1)\n",
    "        context_vec= attn_weights @ v;\n",
    "        return context_vec\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "cfcdf0bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x107db5470>"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "e7d32c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "attn_block=AttentionBlock()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "e0f130e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 0., 0., 0., 0.],\n",
      "        [1., 1., 0., 0., 0., 0.],\n",
      "        [1., 1., 1., 0., 0., 0.],\n",
      "        [1., 1., 1., 1., 0., 0.],\n",
      "        [1., 1., 1., 1., 1., 0.],\n",
      "        [1., 1., 1., 1., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "output=attn_block(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "04da85fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.0772, 0.3565, 0.1479, 0.5331, 0.4066, 0.2318],\n",
      "         [0.4545, 0.9737, 0.4606, 0.5159, 0.4220, 0.5786],\n",
      "         [0.9455, 0.8057, 0.6775, 0.6087, 0.6179, 0.6932],\n",
      "         [0.4354, 0.0353, 0.1908, 0.9268, 0.5299, 0.0950],\n",
      "         [0.5789, 0.9131, 0.0275, 0.1634, 0.3009, 0.5201],\n",
      "         [0.3834, 0.4451, 0.0126, 0.7341, 0.9389, 0.8056]],\n",
      "\n",
      "        [[0.0772, 0.3565, 0.1479, 0.5331, 0.4066, 0.2318],\n",
      "         [0.4545, 0.9737, 0.4606, 0.5159, 0.4220, 0.5786],\n",
      "         [0.9455, 0.8057, 0.6775, 0.6087, 0.6179, 0.6932],\n",
      "         [0.4354, 0.0353, 0.1908, 0.9268, 0.5299, 0.0950],\n",
      "         [0.5789, 0.9131, 0.0275, 0.1634, 0.3009, 0.5201],\n",
      "         [0.3834, 0.4451, 0.0126, 0.7341, 0.9389, 0.8056]]])\n"
     ]
    }
   ],
   "source": [
    "batch=torch.stack([input,input],dim=0)\n",
    "print(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "b5a9b755",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "class MaskedAttentionBlock(nn.Module):\n",
    "    def __init__(self, context_length):\n",
    "        super().__init__()\n",
    "        self.context_len=6;\n",
    "        self.wk=nn.Linear(6,4);\n",
    "        self.wq=nn.Linear(6,4);\n",
    "        self.wv=nn.Linear(6,4);\n",
    "        self.dropout=torch.nn.Dropout(.5)\n",
    "        self.register_buffer('mask',torch.tril(torch.ones(context_length,context_length),diagonal=1))\n",
    "    \n",
    "    def forward(self,x):\n",
    "        b,num_tokens,dim=x.shape                   \n",
    "        q= self.wq(x);\n",
    "        k=self.wk(x);\n",
    "        v= self.wv(x);\n",
    "        attn_scores= q @ k.transpose(1,2)\n",
    "        attn_scores.masked_fill(self.mask.bool()[:num_tokens,:num_tokens], -torch.inf)\n",
    "              \n",
    "        attn_weights= torch.softmax(attn_scores/k.shape[-1]**0.5,dim=-1)\n",
    "        attn_weights=self.dropout(attn_weights)     \n",
    "\n",
    "        context_vec= attn_weights @ v;\n",
    "        return context_vec\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "75fd1fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "block=MaskedAttentionBlock(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "69e46104",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttentionWrapper(nn.Module):\n",
    "    def __init__(self,context_length,heads):\n",
    "        super().__init__();\n",
    "        self.attention_heads=nn.ModuleList([MaskedAttentionBlock(context_length) for _ in range(heads)])\n",
    "    def forward(self, x):\n",
    "        return torch.cat([head(x) for head in self.attention_heads], dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "25e8f723",
   "metadata": {},
   "outputs": [],
   "source": [
    "mthb=MultiHeadAttentionWrapper(6,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "07f15e2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.5483,  0.2711, -0.1395, -0.0766, -0.0293, -0.6766,  0.1983,\n",
       "           0.0731],\n",
       "         [ 0.7867,  0.3218, -0.1234, -0.0414,  0.1032, -0.4606,  0.2253,\n",
       "           0.0929],\n",
       "         [ 0.3118,  0.1745, -0.0995, -0.0499, -0.0153, -0.4542,  0.1040,\n",
       "          -0.0485],\n",
       "         [ 0.8555,  0.5030, -0.2244, -0.1346,  0.0665, -0.9245,  0.2987,\n",
       "           0.1044],\n",
       "         [ 0.5436,  0.3309, -0.1291, -0.0862,  0.0460, -1.0082,  0.3657,\n",
       "           0.2002],\n",
       "         [ 1.0914,  0.5998, -0.2678, -0.1622, -0.0172, -0.2138,  0.0924,\n",
       "           0.1286]],\n",
       "\n",
       "        [[ 0.9291,  0.3749, -0.0282, -0.0925,  0.0209, -1.1143,  0.3571,\n",
       "           0.1531],\n",
       "         [ 1.0296,  0.5232, -0.2772, -0.1126,  0.0343, -0.7808,  0.2338,\n",
       "           0.1339],\n",
       "         [ 0.8469,  0.5052, -0.2354, -0.1378, -0.0997, -0.5310,  0.1521,\n",
       "           0.1548],\n",
       "         [ 1.1542,  0.4226, -0.0142, -0.0581,  0.0658, -0.6776,  0.2974,\n",
       "           0.1476],\n",
       "         [ 0.5436,  0.3309, -0.1291, -0.0862,  0.0778, -0.5822,  0.1719,\n",
       "           0.0841],\n",
       "         [ 0.5368,  0.3623, -0.2433, -0.1165, -0.0626, -0.4123,  0.1547,\n",
       "           0.1803]]], grad_fn=<CatBackward0>)"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mthb(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67be706b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
